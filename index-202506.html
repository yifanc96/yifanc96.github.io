<!DOCTYPE html>
<html lang="en">

<head>
  <!-- Metadata for the Webpage -->
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Yifan Chen</title>

  <!-- Favicons -- We recommend this site for generating favicons: https://www.favicon-generator.org/ -->
  <link rel="apple-touch-icon" sizes="57x57" href="/apple-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="60x60" href="/apple-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/apple-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="/apple-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="/apple-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="/apple-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="/apple-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/apple-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-icon-180x180.png">
  <link rel="icon" type="image/png" sizes="192x192"  href="/android-icon-192x192.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="96x96" href="/favicon-96x96.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <meta name="msapplication-TileColor" content="#ffffff">
  <meta name="msapplication-TileImage" content="/ms-icon-144x144.png">
  <meta name="theme-color" content="#ffffff">

  <!-- Bootstrap CSS files-->
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha384-HSMxcRTRxnN+Bdg0JdbxYKrThecOKuH5zCYotlSAcp1+c8xmyTe9GYg1l9a69psu" crossorigin="anonymous">

  <!-- jQuery UI CSS (optional) -->
  <link rel="stylesheet" href="https://ajax.googleapis.com/ajax/libs/jqueryui/1.12.1/themes/smoothness/jquery-ui.css">

  <!-- Google web fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,400i,600,700" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Montserrat:400,400i,500,500i,600" rel="stylesheet">

  <!-- Font Awesome Web Icons -->
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css" integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous">

  <!-- added by me for github icon-->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  
  <!-- Academicons Courtesy of https://jpswalsh.github.io/academicons/ -->
  <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">

  <!-- Local styles -->
  <link rel="stylesheet" href="css/main.css">

</head>

<body>

  <!-- navbar include -->
  <div w3-include-html="navbar.html"></div>

  <div class="spacer-div-3 hidden-xs hidden-xs"></div>

  <!-- Main content    -->
  <div id="main-container" class="container">

    <div class="row">
      <div class="col-sm-3">
        <img class="center-block img img-responsive img-thumbnail" src="images/beijing_yifan4_small.png" alt="Image of Yifan Chen">
        <!-- <p id="title">Ph.D. in <br>
          <span id="program">Applied and Computational Math</span>
        </p> -->


        <table class="table" id="contact-table">
          <tbody>
            <tr>
              <td>
                </td>
             </tr>
              <!--<td style="width:30px"><i class="fas fa-home"></i></td>-->
              <td>
               Applied Mathematics</td>
            </tr>
            <tr>
              <!--<td style="width:30px"><i class="fas fa-home"></i></td>-->
              <td>
                Office: MS 7304</td>
            </tr>
            <!--<tr>
              <td><i class="fas fa-phone"></i></td>
              <td><a href="tel:9999999999">(626) 298-1480</a></td>
            </tr>-->
            <tr>
              <!--<td><i class="fas fa-at"></i></td>-->
              <td>Email: yifanchen@math.ucla.edu</td>
            </tr>
            <!--<tr>
              <td>Languages: <br>English, Mandarin</td>
            </tr>-->
            <tr>
              <td>Programming: <br>Julia, Python, MATLAB </td>
            </tr>
          </tbody>
        </table>

      </div>
      <div class="col-sm-8 col-sm-offset-1">
        <p>  I am an Assistant Professor in the Department of Mathematics at UCLA. I was previously a Courant Instructor at the Courant Institute, New York University from 2023-2025. I received my Ph.D. from Caltech working with Profs. <a href="http://users.cms.caltech.edu/~hou/">Thomas Y. Hou</a>, <a href="http://users.cms.caltech.edu/~owhadi/">Houman Owhadi</a> and <a href="http://stuart.caltech.edu/">Andrew M. Stuart</a>.
          I obtained my B.S. in Pure and Applied Mathematics at Tsinghua University. 
        </p>
        
        <p> My research lies at the intersection of applied and computational mathematics, applied probability, and statistics. I am interested in probabilistic modeling, inference, and PDEs in scientific computing and data science. I work on the analysis and development of multiscale, stochastic, and randomized algorithms for differential equations, inverse problems, and numerical linear algebra. My recent work focuses on efficient sampling algorithms and generative modeling.

          <p>
          Check out my <a href="research.html">Research Page</a> and <a href="https://scholar.google.com/citations?user=GNiinUoAAAAJ&hl=en">Google Scholar</a> for more details. Feel free to reach out by email if you share similar interest!</p>
        
        
        <h3 class="push-down-3"><span>Topics sketch</span></h3>
        <ul id="topics">
          <div class="panel-group" id="research-topics" role="tablist" aria-multiselectable="true">
            <div class="panel panel-default">
                <div class="panel-heading" role="tab" id="heading-sampling">
                    <h5 class="panel-title">
                        <a role="button" data-toggle="collapse" class="accordion-toggle accordion-plus-toggle collapsed" data-parent="#research-topics" href="#collapse-sampling" aria-expanded="false" aria-controls="collapse-sampling">
                            High dimensional sampling
                        </a>
                    </h5>
                </div>
                <div id="collapse-sampling" class="panel-collapse collapse" role="tabpanel" aria-labelledby="heading-sampling">
                    <div class="panel-body">
                        <br>
                        <p>I work on understanding how high-dimensional sampling can be made feasible and developing efficient algorithms for applications in scientific computing and inverse problems.</p>
                        <ul class="push-down-1" style="line-height: 1.8;">
                            <li style="margin-bottom: 15px;"><strong>Bias delocalization in high dimensions:</strong> Motivated by molecular dynamics applications, we show that unadjusted Langevin samplers can achieve nearly dimension-independent bias scaling when the quantity of interest depends on few variables. Meanwhile, unbiased samplers must scale with dimension via power laws. See <a href="https://arxiv.org/abs/2408.13115">detailed analysis</a>.</li>
                            
                            <li style="margin-bottom: 15px;"><strong>Better scaling for unbiased ensemble samplers:</strong> My work introduces new derivative-free and derivative-based ensemble samplers with affine invariance that improve the popular <a href="https://emcee.readthedocs.io/en/stable/emcee">emcee</a> package, especially in high dimensions. The <a href="https://arxiv.org/abs/2505.02987">affine-invariant HMC</a> achieves state-of-the-art power law scaling as a single-chain counterpart while achieving affine invariance based on complementary ensembles and being embarrassingly parallel.</li>
                            
                            <li style="margin-bottom: 15px;"><strong>Gradient flows and variational inference:</strong> Variational, approximate approaches are often promising in high-dimensional applications. Our work builds a <a href="https://arxiv.org/abs/2310.03597">design framework for gradient flows in sampling</a>. We focus on Fisher-Rao gradient flows as a promising diffeomorphism-invariant approach and establish <a href="https://arxiv.org/abs/2407.15693">functional inequalities in Fisher-Rao geometry</a>. Parametric approximation of gradient flows connects to natural gradients; see <a href="https://link.springer.com/content/pdf/10.1007/s41884-020-00028-0.pdf">Wasserstein natural gradients</a> and also a connection to <a href="https://arxiv.org/abs/2404.01145">sequential-in-time neural Galerkin schemes</a>. We developed a <a href="https://iopscience.iop.org/article/10.1088/1361-6420/ad847b">Kalman filter approximation</a> of Fisher-Rao gradients for efficient, multimodal, derivative-free sampling in large-scale Bayesian inverse problems; see recent <a href="https://arxiv.org/abs/2501.04259">further improvement</a> through specialized high-dimensional quadrature.</li>
                        </ul>
                    </div>
                </div>
            </div>
        
            <div class="panel panel-default">
                <div class="panel-heading" role="tab" id="heading-generative">
                    <h5 class="panel-title">
                        <a role="button" data-toggle="collapse" class="accordion-toggle accordion-plus-toggle collapsed" data-parent="#research-topics" href="#collapse-generative" aria-expanded="false" aria-controls="collapse-generative">
                            Generative modeling and probabilistic inference
                        </a>
                    </h5>
                </div>
                <div id="collapse-generative" class="panel-collapse collapse" role="tabpanel" aria-labelledby="heading-generative">
                    <div class="panel-body">
                        <br>
                        <p>Generative modeling has become a powerful tool for probabilistic inference, especially in high-dimensional data. I work on understanding the mathematical foundations of generative modeling and its usage as generative priors for Bayesian inference with applications in scientific domains.</p>
                        <ul class="push-down-1" style="line-height: 1.8;">
                            <li style="margin-bottom: 15px;"><strong>Probabilistic forecasting with generative modeling:</strong> We develop probabilistic forecasting methods using <a href="https://openreview.net/pdf/9dc86834c15cdb6e583ef6154ec5fa6c51ecee8e.pdf">generative diffusion from a point source</a>, based on stochastic interpolants with applications in fluid and video forecasting. We prove that Föllmer's process—an entropy-minimizing dynamic connecting Dirac measures to target distributions—minimizes a novel statistical estimation error between true and generated samples.</li>
                            
                            <li style="margin-bottom: 15px;"><strong>Posterior sampling with diffusion priors:</strong> I collaborate with scientists on developing rigorous probabilistic imaging methods (see <a href="https://ieeexplore.ieee.org/document/10645293">PnP-MC</a>, <a href="https://openreview.net/pdf?id=Xq9HQf7VNV">PnP-DM</a>, <a href="https://arxiv.org/abs/2503.01161">SGDD</a>) by integrating generative diffusion priors with efficient posterior sampling algorithms. See also <a href="https://openreview.net/pdf?id=T1mIt5exUF">crystal structure generation</a>.</li>
                        </ul>
                    </div>
                </div>
            </div>
        
            <div class="panel panel-default">
                <div class="panel-heading" role="tab" id="heading-statistical">
                    <h5 class="panel-title">
                        <a role="button" data-toggle="collapse" class="accordion-toggle accordion-plus-toggle collapsed" data-parent="#research-topics" href="#collapse-statistical" aria-expanded="false" aria-controls="collapse-statistical">
                            Statistical numerical methods
                        </a>
                    </h5>
                </div>
                <div id="collapse-statistical" class="panel-collapse collapse" role="tabpanel" aria-labelledby="heading-statistical">
                    <div class="panel-body">
                        <br>
                        <p>Recent machine learning approaches for PDEs and inverse problems often treat PDEs as data that describe the relationships between pointwise function evaluations and their derivatives at specific collocation points. By fitting all the data using neural network function approximators, these techniques lead to automatic machine learning-based solvers.</p>
                        
                        <p>Compared to neural networks, the statistical framework based on Gaussian processes (GPs) and its deterministic counterpart kernel methods offer more interpretable and theoretically grounded function approximators, with deep connections to meshless collocation methods and built-in uncertainty quantification. I contribute to a line of work on using GPs to automate the solution of nonlinear PDEs and inverse problems.</p>
                        
                        <ul class="push-down-1" style="line-height: 1.8;">
                            <li style="margin-bottom: 15px;"><strong>Solving PDEs and inverse problems with GPs:</strong> We present a framework with <a href="https://www.sciencedirect.com/science/article/pii/S0021999121005635">algorithms</a>, <a href="https://www.sciencedirect.com/science/article/abs/pii/S0021999124007368">error estimates</a>, and <a href="https://link.springer.com/article/10.1007/s11222-024-10535-0?utm_source=rct_congratemailt&utm_medium=email&utm_campaign=nonoa_20241209&utm_content=10.1007%2Fs11222-024-10535-0">uncertainty quantification</a>.</li>
                            
                            <li style="margin-bottom: 15px;"><strong>Hierarchical parameter learning:</strong> Our work proves the <a href="https://www.ams.org/mcom/0000-000-00/S0025-5718-2021-03649-2/">large data limit for hierarchical parameter learning</a> of covariance kernels of GPs using either probabilistic empirical Bayes or approximation theoretic criteria, which also leads to new results in spatial statistics.</li>
                            
                            <li style="margin-bottom: 15px;"><strong>Fast algorithms with sparse Cholesky:</strong> Our work develops <a href="https://www.ams.org/journals/mcom/0000-000-00/S0025-5718-2024-03992-3/">new adaptations of sparse Cholesky algorithms</a> based on screening effects in spatial statistics that compress the resulting kernel matrices—derived from pointwise evaluations of covariance kernels and their partial derivatives—with state-of-the-art near-linear complexity and new, simpler analysis.</li>
                        </ul>
                        <p>For fast kernel methods in high dimensions, see also <a href="https://onlinelibrary.wiley.com/doi/10.1002/cpa.22234">randomly pivoted Cholesky</a>.</p>
                    </div>
                </div>
            </div>
        
            <div class="panel panel-default">
                <div class="panel-heading" role="tab" id="heading-multiscale">
                    <h5 class="panel-title">
                        <a role="button" data-toggle="collapse" class="accordion-toggle accordion-plus-toggle collapsed" data-parent="#research-topics" href="#collapse-multiscale" aria-expanded="false" aria-controls="collapse-multiscale">
                            Multiscale numerical methods
                        </a>
                    </h5>
                </div>
                <div id="collapse-multiscale" class="panel-collapse collapse" role="tabpanel" aria-labelledby="heading-multiscale">
                    <div class="panel-body">
                        <br>
                        <p>PDEs in physical sciences present significant computational challenges, especially those involving heterogeneous media and high-frequency oscillations. These scenarios require substantial resources to resolve accurate physics. </p>
                        
                        <p>Multiscale methodology has long been advocated to address this problem by identifying low-complexity, homogenized models at coarse scales.</p>
                        
                        <ul class="push-down-1" style="line-height: 1.8;">
                            <li style="margin-bottom: 15px;"><strong>Exponentially convergent multiscale finite element methods:</strong> We develop <a href="https://link.springer.com/article/10.1007/s42967-023-00260-2">ExpMsFEM</a> that extends previous work and achieves exponential convergence of accuracy (see <a href="https://epubs.siam.org/doi/full/10.1137/22M1507802">this paper</a> for 2D Helmholtz equations and <a href="https://epubs.siam.org/doi/abs/10.1137/20M1372214">this paper</a> for rough elliptic equations). This method accurately estimates highly oscillatory solutions with a few specialized basis functions that capture coarse-scale behavior while efficiently incorporating fine-scale features through localized simulations.</li>
                            
                            <li style="margin-bottom: 15px;"><strong>Multiscale upscaling with subsampled data:</strong> <a href="https://epubs.siam.org/doi/abs/10.1137/20M1372214">We propose a novel multiscale method</a> using subsampled coarse variables for upscaling, and the corresponding tight <a href="https://www.aimsciences.org/article/doi/10.3934/dcds.2020296">subsampled Poincaré inequalities</a> for analysis of its accuracy.</li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>

          <!-- <li> New preprint on ''New Affine Invariant Ensemble Samplers and Their Dimensional Scaling'', 2025
            <a href="https://arxiv.org/abs/2505.02987">[arXiv]</a> </li>
          <li> New preprint on ''Convergence of Unadjusted Langevin in High Dimensions: Delocalization of Bias'', 2024
            <a href="https://arxiv.org/abs/2408.13115">[arXiv]</a> </li>
          <li> New preprint on ''Fisher-Rao Gradient Flow: Geodesic Convexity and Functional Inequalities'', 2024
            <a href="https://arxiv.org/abs/2407.15693">[arXiv]</a> </li>
          <li>"Sparse Cholesky Factorization for Solving Nonlinear PDEs via Gaussian Processes" published in Mathematics of Computation, 2024 <a href ="https://www.ams.org/journals/mcom/0000-000-00/S0025-5718-2024-03992-3/">[Journal]</a><a href="https://github.com/yifanc96/PDEs-GP-KoleskySolver">[Code]</a><a href="slides/SparseCholesky_ICERM.pdf"> [Slide]</a></li>
           -->
          <!-- <li>I gave a talk on GP for PDEs in the <a href="https://17.usnccm.org"> 17th U. S. National Congress on Computational Mechanics</a> in New Mexico on July, 2023 <a href="slides/GP-PDE-InvProblems.pdf">[Slide]</a></li>

          <li>
            I gave a talk on sparse Cholesky in the workshop of <a href="https://icerm.brown.edu/topical_workshops/tw-23-msml/"> Mathematical and Scientific Machine Learning</a> at ICERM on June, 2023 <a href="slides/SparseCholesky_ICERM.pdf"> [Slide]</a>
          </li>

          <li>
            I defended my Ph.D. thesis on May 17 2023! <a href="slides/Yifan_thesis_slide.pdf"> [Slide]</a> <a href= "https://thesis.library.caltech.edu/15224/"> [Thesis]</a> 
          </li> -->
      
          <!-- <li>
            I gave a talk at SOCAMS 2023 on gradient flows for sampling on April, 2023 <a href="slides/Slides_Gradient_Flows_For_Sampling_Invariance.pdf"> [Slide]</a>
          </li> -->
        </ul>
 
          <!-- <li>
            I gave a talk at Peking University on Feb, 2023. <a href="slides/Developments of Multiscale and Probabilistic Methods for Solving PDEs and Inverse Problems.pdf">[Slide]</a>
          </li> -->
<!-- 
          <li>
            I gave a talk at Columbia University about Multiscale and Probabilistic Methods in Computation and Inference on Jan, 2023.
          </li> -->

          <!-- <li>I am co-organizing the minisymposium Recent Advances in Kernel Methods for Computing and Learning in <a href ="https://www.siam.org/conferences/cm/conference/mds22">SIAM Mathematics of Data Science</a>, San Diego, Sep 26-30, 2022.</li> -->
          <!-- <li>
            I gave a talk at <a href="https://www.socams.org">SOCAMS</a> in May 21, 2022. <a href="slides/Solving and Learning PDEs with Gaussian Processes_SoCAMS.pdf">[Slide]</a>
          </li>
          <li>
            I did my candidacy talk. <a href="slides/Numerical Computation via Inference.pdf">[Slide]</a>
          </li>
          <li>
            I gave a talk at the <a href="https://www.datasig.ac.uk/event/2022-04-28-yifan-chen">Rough Path Interest Group</a> in April 28, 2022. <a href="slides/Solving and Learning PDEs with Gaussian Processes_Longversion.pdf">[Slide]</a>
          </li>
          <li>
            Gave a talk in SIAM Uncertainty Quantification (UQ22) Minisymposium of New Developments in Gaussian Processes, Atlanta, April 12-15, 2022. <a href="slides/Solving and Learning PDEs with Gaussian Processes.pdf">[Slide]</a>
          </li>

          <li>
            I gave a talk in the <a href="http://cmx.caltech.edu">CMX student seminar</a> on "Multiscale Computation and Parameter Learning for Kernels from PDEs: Two Provable Examples", Nov 2020. <a href="slides/Multiscale_Computation_and_Parameter_Learning.pdf">[Slide]</a>
          </li> -->
          <!-- <li>
            A new <a href="https://www.researchgate.net/publication/344547239_Multiscale_Elliptic_PDEs_Upscaling_and_Function_Approximation_via_Subsampled_Data">paper</a> on "Numerical Upscaling and Function Approximation via Subsampled Data" is online. (Oct 2020)
          </li> -->
          <!-- <li>
           I gave a talk in the session of Kernel Methods at the <a href="http://www.fields.utoronto.ca/activities/20-21/dynamical">Second Symposium on Machine Learning and Dynamical Systems</a>, Fields Institute, Sep 21-25, 2020. See this <a href="https://www.youtube.com/watch?v=88seM_rMllY&list=PLArBKNfJxuun7IjBHqO2x2k4nvPoxqVzt&index=15">YouTube Channel</a>. <a href="slides/consistency_EB_KF_longer.pdf">[Slide]</a>
          </li>
          <li>
            I gave a talk on "Consistency of Hiearchical Parameter Learning" at the <a href="https://www.worldsymposium2020.org/home">Bernoulli-IMS One World Symposium</a>, Aug 2020. Check this <a href="https://www.youtube.com/watch?v=ouEvr7BviXw">YouTube Channel</a>. <a href="slides/consistency_EB_KF.pdf">[Slide]</a>
          </li> -->
          <!-- <li>
            Our <a href="http://www.aimsciences.org/article/doi/10.3934/dcds.2020296?viewType=html">paper</a> on "Function Approximation via the Subsampled Poincare Inequality" has been accepted for publication in <i>Discrete & Continuous Dynamical Systems - A</i>. (Aug 2020)
          </li> -->
          <!--<li>
            A new <a href="https://www.researchgate.net/publication/342923188_Exponential_Convergence_for_Multiscale_Linear_Elliptic_PDEs_via_Adaptive_Edge_Basis_Functions">paper</a> on "Exponential Convergence of Multiscale Methods for Solving Linear Elliptic Equation with Rough Coefficients" is online. (July 2020)
          </li>
          <li>
            A new <a href="https://www.researchgate.net/publication/341640416_Consistency_of_Empirical_Bayes_And_Kernel_Flow_For_Hierarchical_Parameter_Estimation">paper</a> on "Consistency of Hiearchical Parameter Learning of Empirical Bayesian and Kernel Flow Approaches" is online. (May 2020)
          </li>
        -->
          <!--<li>
            Our <a href="https://link.springer.com/article/10.1007/s41884-020-00028-0">paper</a> on "Optimal Transport Natural Gradient" is published in <i>Information Geometry</i>. (May 2020) 
          </li>-->
        
        
      </div>
    </div>

  </div>

  <!-- Back-to-top button -->
  <a role="button" id="topper" data-toggle="tooltip" data-placement="top" title="Top" class="btn scroll-link" href="#top"><i class="fa fa-fw fa-2x fa-caret-up" aria-hidden="true"></i></a>


  <!-- footer include -->
  <div w3-include-html="footer.html"></div>

  <!-- jQuery -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>

  <!-- Bootstrap JS Library -->
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha384-aJ21OjlMXNL5UyIl/XNwTMqvzeRMZH2w8c5cRVpzpU8Y5bApTppSuUkhZXN0VxHd" crossorigin="anonymous"></script>

  <!-- html file include script | used for navbar and footer -->
  <script src="js/w3data.js"></script>
  <script>
    w3IncludeHTML()
  </script>

  <!-- Local scripts -->
  <script src="js/main.js"></script>

  <script>
    $(document).ready(function() {
      $("li#about a").addClass("active");
      $("li#about a").addClass("hvr-bubble-bottom");
    });
  </script>

</body>

</html>
